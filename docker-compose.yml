services:
  # Base de données MongoDB
  mongodb:
    image: mongo:7.0
    container_name: go-api-mongodb
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password123
      MONGO_INITDB_DATABASE: recipes
      TZ: Europe/Paris
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
      - mongodb_config:/data/configdb
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # API Server
  api-server:
    build:
      context: .
      dockerfile: dockerfile
      args:
        VERSION: ${VERSION:-dev}
        GIT_COMMIT: ${GIT_COMMIT:-unknown}
        BUILD_TIME: ${BUILD_TIME:-unknown}
    container_name: go-api-server
    restart: unless-stopped
    environment:
      - PORT=8080
      - ENV=production
      - MONGODB_URI=mongodb://admin:password123@mongodb:27017/recipes?authSource=admin
      - DB_NAME=recipes
      - LOG_LEVEL=info
      - TZ=Europe/Paris
    ports:
      - "8080:8080"
    depends_on:
      mongodb:
        condition: service_healthy
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "exec 3<>/dev/tcp/localhost/8080 && echo -e 'GET /health HTTP/1.1\r\nHost: localhost\r\nConnection: close\r\n\r\n' >&3 && timeout 5s cat <&3 | grep -q '200 OK' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    volumes:
      - api_logs:/app/logs
      - scraper_data:/go_api_mongo_scrapper/scraper

  # Scraper Service
  scraper:
    build:
      context: .
      dockerfile: scraper/dockerfile
      args:
        VERSION: ${VERSION:-dev}
        GIT_COMMIT: ${GIT_COMMIT:-unknown}
        BUILD_TIME: ${BUILD_TIME:-unknown}
    container_name: go-scraper
    restart: "no"  # Le scraper s'exécute une fois puis s'arrête
    environment:
      - SCRAPER_MAX_WORKERS=20
      - SCRAPER_TIMEOUT=30s
      - SCRAPER_BASE_URL=https://www.allrecipes.com
      - SCRAPER_MAX_PAGES=5
      - SCRAPER_MAX_RECIPES_PER_PAGE=20
      - LOG_LEVEL=info
      - TZ=Europe/Paris
    networks:
      - app-network
    volumes:
      - scraper_data:/app/data
    profiles:
      - scraper  # Utiliser 'docker-compose --profile scraper up' pour lancer le scraper

  # MongoDB Express (Interface web pour MongoDB)
  mongo-express:
    image: mongo-express:1.0.0
    container_name: mongo-express
    restart: unless-stopped
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: admin
      ME_CONFIG_MONGODB_ADMINPASSWORD: password123
      ME_CONFIG_MONGODB_URL: mongodb://admin:password123@mongodb:27017/
      ME_CONFIG_BASICAUTH_USERNAME: admin
      ME_CONFIG_BASICAUTH_PASSWORD: admin123
      TZ: Europe/Paris
    ports:
      - "8081:8081"
    depends_on:
      mongodb:
        condition: service_healthy
    networks:
      - app-network
    profiles:
      - tools  # Utiliser 'docker-compose --profile tools up' pour lancer mongo-express

volumes:
  mongodb_data:
    driver: local
  mongodb_config:
    driver: local
  scraper_data:
    driver: local
  api_logs:
    driver: local

networks:
  app-network:
    driver: bridge
    ipam:
      config:
        - subnet: 192.168.100.0/24
